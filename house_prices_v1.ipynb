{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5407,"databundleVersionId":868283,"sourceType":"competition"},{"sourceId":10041719,"sourceType":"datasetVersion","datasetId":6185905}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torch import nn\nfrom torch import optim\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nfrom sklearn.preprocessing import StandardScaler\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-29T19:04:09.684476Z","iopub.execute_input":"2024-11-29T19:04:09.685572Z","iopub.status.idle":"2024-11-29T19:04:09.694486Z","shell.execute_reply.started":"2024-11-29T19:04:09.685528Z","shell.execute_reply":"2024-11-29T19:04:09.693438Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/house-prices-advanced-regression-techniques/sample_submission.csv\n/kaggle/input/house-prices-advanced-regression-techniques/data_description.txt\n/kaggle/input/house-prices-advanced-regression-techniques/train.csv\n/kaggle/input/house-prices-advanced-regression-techniques/test.csv\n/kaggle/input/traintest/train.csv\n/kaggle/input/traintest/test.csv\n","output_type":"stream"}],"execution_count":94},{"cell_type":"code","source":"data_train = pd.read_csv(\"/kaggle/input/traintest/train.csv\")\ndata_test = pd.read_csv(\"/kaggle/input/traintest/test.csv\")\ndata_train = data_train.iloc[:-1]\ndata_train = data_train.fillna(0)\ndata_test = data_test.fillna(0)\ny_train = data_train['SalePrice']\ndata_train = data_train.drop(columns=['SalePrice'])\n\n\n\n\nprint(data_train.isna().sum())  # Для обучающего датасета\nprint(data_test.isna().sum())   # Для тестового датасета\n\n# Проверка после создания dummies\n\ncat_features_mask = (data_train.dtypes == \"object\").values\ncat_features_mask_test = (data_test.dtypes == \"object\").values\n\ndata_train_cat = data_train[data_train.columns[cat_features_mask]]\ndata_test_cat = data_test[data_test.columns[cat_features_mask_test]]\n\n\n\n\n\n\n\ncombined = pd.concat([data_train_cat, data_test_cat], axis=0)\ncombined_dummies = pd.get_dummies(combined, drop_first=True)\ntrain_size = len(data_train_cat)\ndtraincd = combined_dummies[:train_size]  \ndtestcd = combined_dummies[train_size:]\n \ndtraincd = dtraincd.replace({True: 1, False: 0})\ndtestcd = dtestcd.replace({True: 1, False: 0})\n\ntrain_concat = pd.concat([data_train[data_train.columns[~cat_features_mask]], dtraincd], axis=1)\ntest_concat = pd.concat([data_test[data_test.columns[~cat_features_mask_test]], dtestcd], axis=1)\n\nX_train_tensor = torch.tensor(train_concat.values, dtype=torch.float32)\nX_test_tensor = torch.tensor(test_concat.values, dtype=torch.float32)\n\ny_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\ntrain_dataset = TensorDataset(X_train_tensor, y_train_tensor)\ntest_dataset = TensorDataset(X_test_tensor)\n\nprint(train_concat.shape, test_concat.shape)\n\nprint(dtraincd.shape, dtestcd.shape)\nprint(train_concat.isna().sum().sum())  # Для обработанных категориальных признаков (обучающий)\nprint(test_concat.isna().sum().sum())  \n\n\n\ncombined = pd.concat([data_train_cat, data_test_cat], axis=0)\ncombined_dummies = pd.get_dummies(combined, drop_first=True)\ntrain_size = len(data_train_cat)\ndtraincd = combined_dummies[:train_size]  \ndtestcd = combined_dummies[train_size:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T19:04:09.740752Z","iopub.execute_input":"2024-11-29T19:04:09.741144Z","iopub.status.idle":"2024-11-29T19:04:10.265257Z","shell.execute_reply.started":"2024-11-29T19:04:09.741109Z","shell.execute_reply":"2024-11-29T19:04:10.264201Z"}},"outputs":[{"name":"stdout","text":"Id               0\nMSSubClass       0\nMSZoning         0\nLotFrontage      0\nLotArea          0\n                ..\nMiscVal          0\nMoSold           0\nYrSold           0\nSaleType         0\nSaleCondition    0\nLength: 80, dtype: int64\nId               0\nMSSubClass       0\nMSZoning         0\nLotFrontage      0\nLotArea          0\n                ..\nMiscVal          0\nMoSold           0\nYrSold           0\nSaleType         0\nSaleCondition    0\nLength: 80, dtype: int64\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_30/2733095456.py:35: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  dtraincd = dtraincd.replace({True: 1, False: 0})\n/tmp/ipykernel_30/2733095456.py:36: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  dtestcd = dtestcd.replace({True: 1, False: 0})\n","output_type":"stream"},{"name":"stdout","text":"(1459, 268) (1459, 268)\n(1459, 231) (1459, 231)\n0\n0\n","output_type":"stream"},{"name":"stdout","text":"Id               0\nMSSubClass       0\nMSZoning         0\nLotFrontage      0\nLotArea          0\n                ..\nMiscVal          0\nMoSold           0\nYrSold           0\nSaleType         0\nSaleCondition    0\nLength: 80, dtype: int64\nId               0\nMSSubClass       0\nMSZoning         0\nLotFrontage      0\nLotArea          0\n                ..\nMiscVal          0\nMoSold           0\nYrSold           0\nSaleType         0\nSaleCondition    0\nLength: 80, dtype: int64\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_30/979139014.py:35: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  dtraincd = dtraincd.replace({True: 1, False: 0})\n/tmp/ipykernel_30/979139014.py:36: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  dtestcd = dtestcd.replace({True: 1, False: 0})\n","output_type":"stream"},{"name":"stdout","text":"(1459, 268) (1459, 268)\n(1459, 231) (1459, 231)\n0\n0\n","output_type":"stream"}],"execution_count":95},{"cell_type":"code","source":"trainLoader = DataLoader(train_dataset, batch_size=64)\ntestLoader = DataLoader(test_dataset, batch_size=64, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T19:04:10.267396Z","iopub.execute_input":"2024-11-29T19:04:10.267759Z","iopub.status.idle":"2024-11-29T19:04:10.272942Z","shell.execute_reply.started":"2024-11-29T19:04:10.267723Z","shell.execute_reply":"2024-11-29T19:04:10.271762Z"}},"outputs":[],"execution_count":96},{"cell_type":"code","source":"model = nn.Sequential(\n    nn.Linear(268, 512),\n    nn.ReLU(),\n    nn.Linear(in_features=512, out_features=256),\n    nn.ReLU(),\n    nn.Linear(in_features=256, out_features=128),\n    nn.ReLU(),\n    nn.Linear(in_features=128, out_features=64),\n    nn.ReLU(),\n    nn.Linear(in_features=64, out_features=1),\n    \n)\nloss_function = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T19:04:10.274975Z","iopub.execute_input":"2024-11-29T19:04:10.275422Z","iopub.status.idle":"2024-11-29T19:04:10.290400Z","shell.execute_reply.started":"2024-11-29T19:04:10.275371Z","shell.execute_reply":"2024-11-29T19:04:10.289147Z"}},"outputs":[],"execution_count":97},{"cell_type":"code","source":"def run(model, dataloader, loss_function, optimizer=None):\n    # set the model to evaluation or training mode\n    if optimizer is None:\n        model.eval()\n    else:\n        model.train()\n\n    total_loss = 0\n\n    for X, y in dataloader:\n        # Ensure that the input data has the correct shape\n          # Debugging line to check shape\n\n        # Zero the gradients before backward pass\n        optimizer.zero_grad()  # Clear previous gradients\n\n        # compute prediction\n        pred = model(X)\n\n        # compute loss\n        loss = loss_function(pred, y)\n\n        # save loss\n        total_loss += loss.item()\n\n        if optimizer is not None:\n            # compute gradients\n            loss.backward()\n\n            \n\n            # do optimizer step\n            optimizer.step()\n\n    return model.parameters()\n\nNUM_EPOCHS = 20\nfor i in range(NUM_EPOCHS):\n    run(model, trainLoader, loss_function, optimizer)\nprint(\"Model parameters after training:\")\n\n\n# Test phase\ny_test_pred = []\nmodel.eval()  \nwith torch.no_grad(): \n    for X_batch in testLoader:\n        X_batch = X_batch[0]\n        pred = model(X_batch) \n        y_test_pred.append(pred)\n\ny_test_pred = torch.cat(y_test_pred, dim=0).squeeze().numpy()\noutput = pd.DataFrame({'Id': data_test.Id, 'SalePrice': y_test_pred})\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")\ny_test_pred\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T19:04:10.293207Z","iopub.execute_input":"2024-11-29T19:04:10.293694Z","iopub.status.idle":"2024-11-29T19:04:12.728633Z","shell.execute_reply.started":"2024-11-29T19:04:10.293640Z","shell.execute_reply":"2024-11-29T19:04:12.727398Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n  return F.mse_loss(input, target, reduction=self.reduction)\n/opt/conda/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([51])) that is different to the input size (torch.Size([51, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n  return F.mse_loss(input, target, reduction=self.reduction)\n","output_type":"stream"},{"name":"stdout","text":"Model parameters after training:\nYour submission was successfully saved!\n","output_type":"stream"},{"execution_count":98,"output_type":"execute_result","data":{"text/plain":"array([163046.28, 183614.36, 169095.2 , ..., 171990.89, 147845.39,\n       184137.84], dtype=float32)"},"metadata":{}}],"execution_count":98},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}